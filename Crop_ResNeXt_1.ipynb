{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Crop_ResNeXt_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNSy9K05jZpSXYkuedb06py",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BishalMondal/Crop-Disease-Detection/blob/main/Crop_ResNeXt_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ3eTDo2DBmH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Conv_2D_Block(x, model_width, kernel, strides):\n",
        "    # 2D Convolutional Block with BatchNormalization\n",
        "    x = tf.keras.layers.Conv2D(model_width, kernel, strides=strides, padding=\"same\", kernel_initializer=\"he_normal\")(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "KG3w0TvCDNaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def stem_bottleneck(inputs, num_filters):\n",
        "    # Construct the Stem Convolution Group\n",
        "    # inputs : input vector\n",
        "    # First Convolutional layer, where pooled feature maps will be reduced by 75%\n",
        "    conv = Conv_2D_Block(inputs, num_filters, (7, 7), (2, 2))\n",
        "    if conv.shape[1] <= 2:\n",
        "        pool = tf.keras.layers.MaxPooling2D(pool_size=(1, 1), strides=(2, 2), padding=\"valid\")(conv)\n",
        "    else:\n",
        "        pool = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding=\"valid\")(conv)\n",
        "\n",
        "    return pool"
      ],
      "metadata": {
        "id": "TmwR7TF2DV2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block(inputs, num_filters):\n",
        "    # Construct Block of Convolutions without Pooling\n",
        "    # x        : input into the block\n",
        "    # n_filters: number of filters\n",
        "    conv = Conv_2D_Block(inputs, num_filters, (3, 3), (2, 2))\n",
        "    conv = Conv_2D_Block(conv, num_filters, (3, 3), (1, 1))\n",
        "\n",
        "    return conv"
      ],
      "metadata": {
        "id": "LpqCUfPcDks-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def grouped_convolution_block(inputs, num_filters, kernel_size, strides, cardinality):\n",
        "    # Adds a grouped convolution block\n",
        "    group_list = []\n",
        "    grouped_channels = int(num_filters / cardinality)\n",
        "\n",
        "    if cardinality == 1:\n",
        "        # When cardinality is 1, it is just a standard convolution\n",
        "        x = Conv_2D_Block(inputs, num_filters, (1, 1), strides=(strides, strides))\n",
        "        x = Conv_2D_Block(x, grouped_channels, (kernel_size, kernel_size), (strides, strides))\n",
        "\n",
        "        return x\n",
        "\n",
        "    for c in range(cardinality):\n",
        "        x = tf.keras.layers.Lambda(lambda z: z[:, :, :, c * grouped_channels:(c + 1) * grouped_channels])(inputs)\n",
        "        x = Conv_2D_Block(x, num_filters, (1, 1), strides=(strides, strides))\n",
        "        x = Conv_2D_Block(x, grouped_channels, (kernel_size, kernel_size), strides=(strides, strides))\n",
        "\n",
        "        group_list.append(x)\n",
        "\n",
        "    group_merge = tf.keras.layers.concatenate(group_list, axis=-1)\n",
        "    x = tf.keras.layers.BatchNormalization()(group_merge)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "\n",
        "    return x"
      ],
      "metadata": {
        "id": "7dVj69hiDpRZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_block_bottleneck(inputs, num_filters, cardinality):\n",
        "    # Construct a Residual Block of Convolutions\n",
        "    # x        : input into the block\n",
        "    # n_filters: number of filters\n",
        "    shortcut = Conv_2D_Block(inputs, num_filters * 2, (1, 1), (1, 1))\n",
        "    #\n",
        "    x = grouped_convolution_block(inputs, num_filters, 3, 1, cardinality)\n",
        "    x = Conv_2D_Block(x, num_filters * 2, (1, 1), (1, 1))\n",
        "    #\n",
        "    conv = tf.keras.layers.Add()([x, shortcut])\n",
        "    out = tf.keras.layers.Activation('relu')(conv)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "OKQKudJODvqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def residual_group_bottleneck(inputs, num_filters, n_blocks, cardinality, conv=True):\n",
        "    # x        : input to the group\n",
        "    # n_filters: number of filters\n",
        "    # n_blocks : number of blocks in the group\n",
        "    # conv     : flag to include the convolution block connector\n",
        "    out = inputs\n",
        "    for _ in range(n_blocks):\n",
        "        out = residual_block_bottleneck(out, num_filters, cardinality)\n",
        "\n",
        "    # Double the size of filters and reduce feature maps by 75% (strides=2, 2) to fit the next Residual Group\n",
        "    if conv:\n",
        "        out = conv_block(out, num_filters * 2)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "3N6rXYYUDzoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def learner152(inputs, num_filters, cardinality):\n",
        "    # Construct the Learner\n",
        "    x = residual_group_bottleneck(inputs, num_filters, 3, cardinality)  # First Residual Block Group of 64 filters\n",
        "    x = residual_group_bottleneck(x, num_filters * 2, 7, cardinality)  # Second Residual Block Group of 128 filters\n",
        "    x = residual_group_bottleneck(x, num_filters * 4, 35, cardinality)  # Third Residual Block Group of 256 filters\n",
        "    out = residual_group_bottleneck(x, num_filters * 8, 2, cardinality, False)  # Fourth Residual Block Group of 512 filters\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "URTkRBMEEEZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classifier(inputs, class_number):\n",
        "    # Construct the Classifier Group\n",
        "    # inputs       : input vector\n",
        "    # class_number : number of output classes\n",
        "    out = tf.keras.layers.Dense(class_number, activation='softmax')(inputs)\n",
        "\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "N4kElycgD5Gj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def regressor(inputs, feature_number):\n",
        "    # Construct the Regressor Group\n",
        "    # inputs       : input vector\n",
        "    # feature_number : number of output features\n",
        "    out = tf.keras.layers.Dense(feature_number, activation='linear')(inputs)\n",
        "\n",
        "    return out"
      ],
      "metadata": {
        "id": "uyRHB9LZEH02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNeXt:\n",
        "    def __init__(self, length, width, num_channel, num_filters, cardinality=4, problem_type='Classification',\n",
        "                 output_nums=1, pooling='avg', dropout_rate=False):\n",
        "        self.length = length\n",
        "        self.width = width\n",
        "        self.num_channel = num_channel\n",
        "        self.num_filters = num_filters\n",
        "        self.cardinality = cardinality\n",
        "        self.problem_type = problem_type\n",
        "        self.output_nums = output_nums\n",
        "        self.pooling = pooling\n",
        "        self.dropout_rate = dropout_rate\n",
        "\n",
        "    def MLP(self, x):\n",
        "        outputs = []\n",
        "        if self.pooling == 'avg':\n",
        "            x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "        elif self.pooling == 'max':\n",
        "            x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
        "        # Final Dense Outputting Layer for the outputs\n",
        "        x = tf.keras.layers.Flatten(name='flatten')(x)\n",
        "        if self.dropout_rate:\n",
        "            x = tf.keras.layers.Dropout(self.dropout_rate, name='Dropout')(x)\n",
        "        outputs = tf.keras.layers.Dense(self.output_nums, activation='linear')(x)\n",
        "        if self.problem_type == 'Classification':\n",
        "            outputs = tf.keras.layers.Dense(self.output_nums, activation='softmax')(x)\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def ResNeXt152(self):\n",
        "        inputs = tf.keras.Input((self.length, self.width, self.num_channel))  # The input tensor\n",
        "        stem_b = stem_bottleneck(inputs, self.num_filters)  # The Stem Convolution Group\n",
        "        x = learner152(stem_b, self.num_filters, self.cardinality)  # The learner\n",
        "        outputs = self.MLP(x)\n",
        "        # Instantiate the Model\n",
        "        model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "jua-w-SnE4Px"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}